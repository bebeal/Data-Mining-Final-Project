{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e04ad8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ddd23d",
   "metadata": {},
   "source": [
    "# Intro\n",
    "The relationship between the musical characteristics of each song and the popularity of each song is important for music production and song artists companies to create the next bit songs hits. This Spotify dataset contains songs that were on the Top 200 Weekly Global charts for Spotify in 2020 & 2021 along with each songâ€™s genre, song artist ID, and various musical attributes. The highest charting position of each song is a number that indicates the highest position the song ever ranked. In this project, we will attempt to predict song genre based on both song metadata as well as musical features generated by Spotify in-house algorithms. We will also try to predict the highest charting position of each song. Our classification algorithm can be used by musical production companies and song artists to gauge how certain metrics relate to genre, how genre can be predicted based on these features, and how these features relate to the ability of the song to make the top charts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e8b6d",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "This dataset contains songs that were on the Top 200 Weekly Global charts for Spotify in 2020 & 2021. For each song, we have the following features.\n",
    "\n",
    "| Feature                   | Feature Type |\n",
    "|---------------------------|--------------|\n",
    "| Highest Charting Position | Numeric      |\n",
    "| Number of Times Charted   | Numeric      |\n",
    "| Song Name                 | Categorical  |\n",
    "| Song ID                   | Categorical  |\n",
    "| Artist                    | Categorical  |\n",
    "| Streams                   | Numeric      |\n",
    "| Artist Followers          | Numeric      |\n",
    "| Genre                     | Categorical  |\n",
    "| Release Date              | Numeric      |\n",
    "| Weeks Charted             | Numeric      |\n",
    "| Popularity                | Numeric      |\n",
    "| Danceability              | Numeric      |\n",
    "| Acousticness              | Numeric      |\n",
    "| Energy                    | Numeric      |\n",
    "| Instrumentalness          | Numeric      |\n",
    "| Loudness                  | Numeric      |\n",
    "| Speechiness               | Numeric      |\n",
    "| Tempo                     | Numeric      |\n",
    "| Valence                   | Numeric      |\n",
    "| Chord                     | Categorical  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af52438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire Dataset\n",
    "path = 'spotify_dataset.csv'\n",
    "data = pd.DataFrame(pd.read_csv(path))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638baf8c",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d07d99",
   "metadata": {},
   "source": [
    "### Removing irrelevant columns and missing values\n",
    "For our analysis, we will exclude song name and song ID from our feature set. These features do not give any information that would be pertinent to classifying the genre of each song. We will also drop any records that do not have any classified song genres, chords, or duration recorded as these are considered incomplete records. We chose to drop these records as opposed to replacing values with the mean for that feature because each song varies significatly in terms of its features and there is no \"true average\" for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns corresponding to: index, song name, song id\n",
    "columns_to_exclude = [0, 4, 8]\n",
    "data.drop(columns=data.columns[columns_to_exclude], inplace=True)\n",
    "\n",
    "# some songs have no defined Chord\n",
    "print('Songs with no defined Chord', np.sum([data['Chord'] == ' ']))\n",
    "# some song have not defined genre\n",
    "print(\"Song with no defined genre\", np.sum([data['Genre'] == '[]']))\n",
    "# some songs have no defined duration\n",
    "print('Songs with no defined Duration', np.sum([data[\"Duration (ms)\"] == ' ']))\n",
    "\n",
    "# Drop rows with missing values\n",
    "data['Chord'].replace(' ', np.nan, inplace=True)\n",
    "data['Genre'].replace('[]', np.nan, inplace=True)\n",
    "data['Duration (ms)'].replace(' ', np.nan, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151704f2",
   "metadata": {},
   "source": [
    "### Fixing Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17833fcd",
   "metadata": {},
   "source": [
    "This was done to make the calculations and comparisons during exploration easier since each feature would have the same data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing dtypes of values, so that they're floats\n",
    "data['Streams'] = [int(stream.replace(',', '')) for stream in data['Streams'].tolist()]\n",
    "types = {'Artist Followers':'int64', 'Duration (ms)':'int64', 'Popularity':'float','Danceability':'float', 'Acousticness':'float', 'Energy':'float', 'Liveness':'float','Loudness':'float', 'Speechiness':'float', 'Tempo':'float', 'Valence':'float'}\n",
    "data = data.astype(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defbb99",
   "metadata": {},
   "source": [
    "### Mapping Categorical Features to Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc676a2",
   "metadata": {},
   "source": [
    "We mapped the artist feature to a new feature \"Artist Class\". This avoids dealing with string names in classification and instead, each artist corresponds to a unique identifier for that artist. The chord feature and genre feature were also engineered into new classes \"Chord Class\" and \"Genre Class\" for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3645a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Converting each artist to a class\n",
    "artists = data['Artist'].tolist()\n",
    "artists_set = set()\n",
    "for artist in artists:\n",
    "    multiple_artists = artist.split(\", \")\n",
    "    for each_artist in multiple_artists:\n",
    "        artists_set.add(each_artist)\n",
    "\n",
    "classes = range(len(artists_set))\n",
    "artists_to_class = dict(zip(artists_set, classes))\n",
    "\n",
    "# Adding classes as a column\n",
    "artist_column = [[artists_to_class.get(each_artist) for each_artist in artist.split(\", \")] for artist in artists]\n",
    "data.insert(5, 'Artist_Class', artist_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d756ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each chord to a class\n",
    "chords = set(data['Chord'].tolist())\n",
    "\n",
    "classes = range(len(chords))\n",
    "chords_to_class = dict(zip(chords, classes))\n",
    "\n",
    "# Adding classes as a column\n",
    "chord_column = [chords_to_class.get(chord_name) for chord_name in data['Chord'].tolist()]\n",
    "data['Chord_Class'] = chord_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780ada0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popular = [\"pop\", \"rock\", \"rap\", \"hiphop\", \"country\", \"latin\", \"other\"]\n",
    "latin = [\"mexican\", \"sertanejo\", \"forro\", \"piseiro\", \"latin\", \"espanol\"]\n",
    "genres = []\n",
    "\n",
    "# Checks if a genre is a latin genre\n",
    "def is_latin(genre):\n",
    "    for latin_genre in latin:\n",
    "        if latin_genre in genre:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "genre_feat = data[\"Genre\"].tolist()\n",
    "for feat_list in genre_feat:\n",
    "    # Parse genres\n",
    "    temp = feat_list.replace(\"'\", \"\")\n",
    "    temp = temp.replace(\"[\", \"\")\n",
    "    temp = temp.replace(\"]\", \"\")\n",
    "    temp = temp.replace(\" \", \"\")\n",
    "    feats  = temp.split(\",\")\n",
    "    song_genre = set()\n",
    "    # Replace all pop, rock, rap, and hiphop genres with general genres\n",
    "    for feat in feats:\n",
    "        if \"pop\" in feat:\n",
    "            song_genre.add(\"pop\")\n",
    "        elif \"rock\" in feat:\n",
    "            song_genre.add(\"rock\")\n",
    "        elif \"rap\" in feat or \"brooklyndrill\" in feat:\n",
    "            song_genre.add(\"rap\")\n",
    "        elif \"hiphop\" in feat:\n",
    "            song_genre.add(\"hiphop\")\n",
    "        elif \"country\" in feat:\n",
    "            song_genre.add(\"country\")\n",
    "        elif is_latin(feat):\n",
    "            song_genre.add(\"latin\")\n",
    "    if (len(song_genre) == 0):\n",
    "        song_genre.add(\"other\")\n",
    "    genres.append(song_genre)\n",
    "        \n",
    "# Find genre frequencies\n",
    "genre_freq = Counter([genre for song_genres in genres for genre in song_genres])\n",
    "# Replace song genres with the most common genre\n",
    "for i in range(len(genres)):\n",
    "    song_genres = list(genres[i])\n",
    "    max_freq_genre = None\n",
    "    max_freq = -1\n",
    "    for j in range(len(song_genres)):\n",
    "        if song_genres[j] in genre_freq:\n",
    "            cur_freq = genre_freq.get(song_genres[j])\n",
    "            if max_freq < cur_freq:\n",
    "                max_freq = cur_freq\n",
    "                max_freq_genre = song_genres[j]\n",
    "    genres[i] = max_freq_genre\n",
    "\n",
    "# Converting each genre to a class\n",
    "unique_genres = set(genres)\n",
    "\n",
    "classes = range(len(unique_genres))\n",
    "genres_to_class = dict(zip(unique_genres, classes))\n",
    "\n",
    "# Adding classes as a column\n",
    "genre_column = [genres_to_class.get(genre_name) for genre_name in genres]\n",
    "data['Genre_Class'] = genre_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25edb52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd469f6",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3e9b9",
   "metadata": {},
   "source": [
    "After some data preparation, we explored the features and plotted their ranges to visualize any outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0c394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exploring and Checking for Noise and Outliers\n",
    "\n",
    "stream_bins = list(range(0, 10000001, 1000000)) + [99999999]\n",
    "# streams = [int(stream.replace(',', '')) for stream in data['Streams'].tolist()]\n",
    "hist, bin_edges = np.histogram(data['Streams'], bins=stream_bins)\n",
    "percentages = hist/np.sum(hist)\n",
    "labels = np.array(['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90-100', '100+'])\n",
    "labels = labels[percentages != 0]\n",
    "percentages = percentages[percentages != 0]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.pie(percentages, labels=labels)\n",
    "ax.set_title('Number of Streams (millions)')\n",
    "plt.show()\n",
    "\n",
    "# should sort chords from low to high?\n",
    "ax = data['Chord'].value_counts().plot.bar()\n",
    "ax.set_title('Chords')\n",
    "plt.show()\n",
    "\n",
    "duration_bins = list(range(0, 30000*2*10, 30000))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(pd.to_numeric(data[\"Duration (ms)\"]), bins=duration_bins)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.set_title('Histogram of duration(ms)')\n",
    "plt.show()\n",
    "\n",
    "zero_to_one_bins = np.linspace(0.1, 1.0, 10)\n",
    "fig, ax = plt.subplots(2, 3, constrained_layout=True)\n",
    "zero_to_one_columns = ['Danceability', 'Acousticness', 'Energy', 'Liveness', 'Speechiness', 'Valence']\n",
    "for i in range(len(zero_to_one_columns)):\n",
    "    idx = np.unravel_index(i, (2, 3))\n",
    "    ax[idx].hist(pd.to_numeric(data[zero_to_one_columns[i]]), bins=zero_to_one_bins)\n",
    "    ax[idx].set_title(zero_to_one_columns[i])\n",
    "fig.suptitle('Histograms')\n",
    "plt.show()\n",
    "\n",
    "duration_bins = list(range(0, max(data['Streams']), 1000000))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(pd.to_numeric(data[\"Streams\"]), bins=duration_bins)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.set_title('Histogram of Stream Count')\n",
    "plt.show()\n",
    "\n",
    "duration_bins = list(range(0, max(data['Highest Charting Position']), 10))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(pd.to_numeric(data['Highest Charting Position']), bins=duration_bins)\n",
    "ax.ticklabel_format(style='plain')\n",
    "ax.set_title('Histogram of Highest Charting Positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring \n",
    "\n",
    "data.groupby('Number of Times Charted').describe()['Highest Charting Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ec157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring\n",
    "numeric_data = data.drop([\"Chord_Class\", \"Genre_Class\"], axis=1)\n",
    "sns.heatmap(data.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57334fc",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data a bit more\n",
    "# drop non-number data (including data we've converted to numbers)\n",
    "cols_to_drop = ['Week of Highest Charting', 'Artist', 'Genre', 'Release Date', 'Weeks Charted', 'Chord']\n",
    "data_only_nums = data.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# only consider first artist for ease, round streams\n",
    "data_only_nums['Artist_Class'] = data_only_nums.apply(lambda x: x[0], axis=1)\n",
    "\n",
    "# round streams so we have a chance at predicting it well\n",
    "data_only_nums['Streams'] = (data_only_nums['Streams'] / 10000000).astype(int) * 10000000\n",
    "data_only_nums['Artist Followers'] = (data_only_nums['Artist Followers'] / 100000).astype(int) * 100000\n",
    "data_only_nums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea576c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data/labels frames\n",
    "genre_labels = data_only_nums['Genre_Class'].values.ravel()\n",
    "genre_data = data_only_nums.drop(['Genre_Class'], axis=1)\n",
    "\n",
    "charting_labels = data_only_nums['Highest Charting Position'].values\n",
    "charting_data = data_only_nums.drop(['Highest Charting Position'], axis=1)\n",
    "\n",
    "# Bin the highest charting positions\n",
    "discretize = KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='uniform')\n",
    "charting_labels = np.array(charting_labels).reshape(-1, 1)\n",
    "discretize.fit(charting_labels)\n",
    "charting_labels = pd.Series(discretize.transform(charting_labels).flatten())\n",
    "\n",
    "\n",
    "print('Genre Data Shape:', genre_data.shape, '\\nGenre Labels Shape:', len(genre_labels))\n",
    "print('Charting Data Shape:', charting_data.shape, '\\nCharting Labels Shape:', len(charting_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e8b6e",
   "metadata": {},
   "source": [
    "## Class Imbalances \n",
    "From our visualization of the song genres, it is apparent that there are many more pop and rap records represented in the Spotify dataset than the other song genres. To address this class imbalance, we will use the TomkLinks method implemented by the *imblearn* package which undersamples the majority classes to balance the dataset. It is notable that the imblearn's pipeline does not apply the TomkLinks to the test set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should sort chords from low to high?\n",
    "ax = data['Genre_Class'].value_counts().plot.bar()\n",
    "ax.set_title('Song Genre')\n",
    "genre_names = [name for name, _ in genre_freq.most_common(len(popular))]\n",
    "ax.set_xticklabels(labels=genre_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e7c92",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "For our data analysis, we will train four classifiers on both predicing song genre and highest charting position. The four classifier will be use are:\n",
    "\n",
    "1. Decision Tree\n",
    "2. K-Nearest Neighbors\n",
    "3. Adaboost\n",
    "4. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5ce92",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def do_decision_tree(data, labels, label_name):\n",
    "    # fit a decision tree classifier across 5 cross folds\n",
    "    clf = DecisionTreeClassifier(criterion='entropy')\n",
    "    \n",
    "    pipe = make_pipeline_with_sampler(        \n",
    "                                    TomekLinks(),\n",
    "                                    clf\n",
    "            )\n",
    "\n",
    "    # Create grid search\n",
    "    param_grid = {\n",
    "        'decisiontreeclassifier__criterion': [\"gini\", \"entropy\"],\n",
    "        'decisiontreeclassifier__max_depth': list(range(1, 10, 2))\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "    # Perform Cross Validation\n",
    "    preds = cross_val_predict(grid_search, data, labels, cv=10)\n",
    "    print('Accuracy:', (accuracy_score(labels, preds) * 100))\n",
    "    print(classification_report(labels, preds, zero_division=0))\n",
    "    \n",
    "print(\"Genre Classification\")\n",
    "do_decision_tree(genre_data, genre_labels, 'Genre')\n",
    "print(\"Charting Position Classification\")\n",
    "do_decision_tree(charting_data, charting_labels, 'Highest Charting Position')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e81a46",
   "metadata": {},
   "source": [
    "### Results\n",
    "A decision tree working this well with our data is surprising, especially with how well it can predict charting position! This is likely due to the fact that there are a lot of numerical features such as danceability and energy. This allows the tree to split on these features and make more accurate predictions.\n",
    "\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def do_knn(data, labels, label_name):\n",
    "\n",
    "    numeric_feat = [\"Danceability\", \"Energy\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Tempo\", \n",
    "                    \"Duration (ms)\", \"Valence\", \"Artist Followers\", \"Popularity\", \"Number of Times Charted\", \"Streams\"]\n",
    "\n",
    "    cat_feat = [\"Artist_Class\", \"Chord_Class\"]\n",
    "\n",
    "\n",
    "    # Add chart pos as feat for genre classifier\n",
    "    if label_name == \"Genre\":\n",
    "        numeric_feat.append(\"Highest Charting Position\")\n",
    "    # Add genre as feat for char pos classifier\n",
    "    else:\n",
    "        cat_feat.append(\"Genre_Class\")\n",
    "\n",
    "    # Don't process features that we dropped for testing\n",
    "    numeric_feat = [feat for feat in numeric_feat if feat in data.columns]\n",
    "    cat_feat = [feat for feat in cat_feat if feat in data.columns]\n",
    "\n",
    "    # Sampler\n",
    "    sampler = TomekLinks()\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scalar = StandardScaler()\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Create feature transformation pipeline\n",
    "    numeric_transform = make_pipeline_with_sampler(scalar, pca)\n",
    "    cat_transform = make_pipeline_with_sampler(encoder)\n",
    "\n",
    "    feat_transform = ColumnTransformer(\n",
    "                            transformers=[ ('num_transform', numeric_transform, numeric_feat),\n",
    "                                        ('cat_transform', cat_transform, cat_feat)]\n",
    "    )\n",
    "\n",
    "    # KNN \n",
    "    knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    # Pipeline \n",
    "    pipe = make_pipeline_with_sampler(\n",
    "                                    sampler,\n",
    "                                    feat_transform,\n",
    "                                    knn\n",
    "            )\n",
    "\n",
    "    # Create grid search\n",
    "    param_grid = {\n",
    "        'kneighborsclassifier__n_neighbors': list(range(1, 10, 2))\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Perform Cross Validation\n",
    "    preds = cross_val_predict(grid_search, data, labels, cv=10)\n",
    "    print('Accuracy:', (accuracy_score(labels, preds) * 100))\n",
    "    print(classification_report(labels, preds, zero_division=0))\n",
    "\n",
    "print(\"Genre Classification\")\n",
    "do_knn(genre_data, genre_labels, \"Genre\")\n",
    "print(\"Charting Position Classification\")\n",
    "do_knn(charting_data, charting_labels, \"Highest Charting Position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40b3ee",
   "metadata": {},
   "source": [
    "### Results\n",
    "While KNN performed similarly to the decision tree for predicting genre, KNN did much worse with predicting highest charting position. In order to try and improve this classification, we will reduce the dimensionality of our data by pruning extraneous features and only including columns like \"danceability\", \"tempo\", etc which are directly related to the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_drop_cols = ['Highest Charting Position', 'Number of Times Charted', 'Streams', 'Artist_Class', 'Artist Followers', 'Popularity']\n",
    "charting_drop_cols = ['Genre_Class', 'Number of Times Charted', 'Streams', 'Artist_Class', 'Artist Followers', 'Popularity']\n",
    "new_genre_data = genre_data.drop(genre_drop_cols, axis=1)\n",
    "new_charting_data = charting_data.drop(charting_drop_cols, axis=1)\n",
    "\n",
    "do_knn(new_genre_data, genre_labels, 'New Genre')\n",
    "do_knn(new_charting_data, charting_labels, 'New Highest Charting Position')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091a253",
   "metadata": {},
   "source": [
    "This general dimensionality reduction actually reduced the accuracy of KNN in predicting highest charting position. This may be reconciled based on the information we lost during reduction. It is possible that artists with more followers will probably tend to have higher charting positions with their song than someone else who may happen to have a similar \"danceability\" rating. Because of this, features like artist followers that are not directly related to the song may allow for better prediction of charting position than features more correlated with the song like dancability and tempo since these are more generalized across the music industry.\n",
    "\n",
    "## Ensemble (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613919e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def do_adaboost(data, labels, label_name):\n",
    "    data = data.values\n",
    "    tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    clf = AdaBoostClassifier(base_estimator=tree, n_estimators=25)\n",
    "\n",
    "    pipe = make_pipeline_with_sampler(\n",
    "        TomekLinks(),\n",
    "        clf\n",
    "    )\n",
    "    \n",
    "    preds = cross_val_predict(pipe, data, labels, cv=10)\n",
    "    print('Accuracy:', (accuracy_score(labels, preds) * 100))\n",
    "    print(classification_report(labels, preds, zero_division=0))\n",
    "\n",
    "do_adaboost(genre_data, genre_labels, 'Genre')\n",
    "do_adaboost(charting_data, charting_labels, 'Highest Charting Position')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc37e5e",
   "metadata": {},
   "source": [
    "### Results\n",
    "The ensemble method of classification does a similar job at classifying genre as decision trees and KNN. However, it is very accurate in terms of prediction highest charting position. This is likely because AdaBoost is boosting the more difficult to classify records and giving them a higher weight in the next model instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'nn__hidden_layer_sizes': list(zip(range(100, 501, 100))),\n",
    "    'nn__activation': ['relu', 'logistic'],\n",
    "    'nn__learning_rate_init':[0.001, 0.0001]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('nn', MLPClassifier(learning_rate='adaptive'))])\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# To suppress warning\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "accuracies = cross_val_score(grid_search, genre_data, genre_labels, cv=5)\n",
    "print('Accuracies of Folds:', accuracies)\n",
    "print('Average Accuracy: %.4f%%' % (accuracies.mean() * 100))\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(grid_search, charting_data, charting_labels, cv=5)\n",
    "print('Accuracies of Folds:', accuracies)\n",
    "print('Average Accuracy: %.4f%%' % (accuracies.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f374c54",
   "metadata": {},
   "source": [
    "## Overall Conclusions\n",
    "In order to predict genre and highest charting position, we used three classifiers: decision tree, KNN, and ensemble method with boosting. Prior to classification, in data preparation, we removed extraneous features such as song ID and mapped categorical features to numeric. Then, in data exploration, we visualized the range of each feature to easily remove any noise in the data or outliers for a particular feature. For feature engineering, we modulated some features for easier classification such as only considering the first artist on the song and rounding streams for better predictions. We also did one hot encoding for some of the categorical features. In the data exploration phase, we found that a majority of the records were from the pop and rap genres resulting in a class imbalance. In order to compensate for this, we used TomkLinks which undersamples the majority class to offset the imbalance. Then, the data was ready for classiication. For genre, the accuracy of predictions were around 63% (decision tree), 59% (KNN), and 57%(ensemble boosting). These accuracies are all pretty similar with decision tree doing the best. For highest charting position, the prediction accuracies were 100% (decision tree), 12.58% (KNN), and 99.18% (ensemble boosting). We attempted to improve the accuracy of the KNN classifier through dimensionality reduction, but this actually diminished the accuracy. This is likely due to the fact that when dimensionality is reduced, information is lost from the dataset that may be useful to the classfier. Overall, the decision tree classifier performed the best at predicting the genre and highest charting position of the songs in this Spotify dataset."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35926c5d777408397385bd09a40c7111f79ffc439e76f20fc1c4992064d08fc3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
